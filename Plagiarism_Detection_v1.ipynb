{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EE19B145 Siddharth Nilesh Ambekar (ANYONE WHO MAKES MODIFICATIONS SHOULD ADD THEIR NAME HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from string import punctuation\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "import re \n",
    "\n",
    "alph='abcdefghijklmnopqrstuvwxyz';\n",
    "num='0123456789';\n",
    "Map={alph[i]:i for i in range(len(alph))};\n",
    "NumMap={num[i]:i for i in range(len(num))};\n",
    "Map.update(NumMap);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullCleanup(t):  #This function is useful for cosine similarity, and substring matching\n",
    "    d=t.replace('\\n',' ');\n",
    "    L=re.split(r'\\W+',d);\n",
    "    L=[i.lower() for i in L];\n",
    "    bucket=[];\n",
    "    stop_words=set(stopwords.words('english'))-{'won','not'};\n",
    "    for i in L:\n",
    "        if i in stop_words or len(i)<=2:\n",
    "            continue;\n",
    "        else:\n",
    "            bucket+=[i];\n",
    "    lemmatiser=WordNetLemmatizer();\n",
    "    bucket=[lemmatiser.lemmatize(i,pos='v') for i in bucket];\n",
    "    bucket=[lemmatiser.lemmatize(i,pos='n') for i in bucket];\n",
    "    bucket=[lemmatiser.lemmatize(i,pos=wordnet.ADJ) for i in bucket];\n",
    "    bucket=[lemmatiser.lemmatize(i,pos=wordnet.ADV) for i in bucket];\n",
    "    return bucket;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION BREAKS THE GIVEN DOCUMENT INTO ITS COMPONENT SENTENCES.\n",
    "def SentenceBreak(doc):  \n",
    "    d=doc.replace('\\n',' ');\n",
    "    d1=d.lower();\n",
    "    n=len(d1);\n",
    "    ind=0;\n",
    "    b=[];\n",
    "    for i in range(n):\n",
    "        if d1[i]=='.' or d1[i]=='!' or d1[i]=='?':\n",
    "            if ind==0:\n",
    "                b+=[d1[ind:i]];\n",
    "                ind=i;\n",
    "            else:\n",
    "                b+=[d1[ind+2:i]];\n",
    "                ind=i;\n",
    "    return b;            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectoriser(doc):\n",
    "    L=fullCleanup(doc);\n",
    "    LDict={};\n",
    "    for i in L:\n",
    "        LDict.setdefault(i,None);\n",
    "        if LDict[i]!=None:\n",
    "            LDict[i]+=1;\n",
    "        else:\n",
    "            LDict[i]=1;\n",
    "    return LDict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountVectorise(doc1,doc2):\n",
    "    LDict1=Vectoriser(doc1);\n",
    "    LDict2=Vectoriser(doc2);\n",
    "    basis={};\n",
    "    for i in LDict1:\n",
    "        basis.setdefault(i,0);\n",
    "        basis[i]=1;\n",
    "    for j in LDict2:\n",
    "        basis.setdefault(j,0);\n",
    "        basis[j]=1;\n",
    "    D1=[];\n",
    "    D2=[];\n",
    "    for k in basis:\n",
    "        LDict1.setdefault(k,0);\n",
    "        LDict2.setdefault(k,0);\n",
    "        D1+=[[k,LDict1[k]]];\n",
    "        D2+=[[k,LDict2[k]]];\n",
    "    return [D1,D2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosineSimilarity(doc1,doc2):\n",
    "    V=CountVectorise(doc1,doc2);\n",
    "    v1=np.array([V[0][k][1] for k in range(len(V[0]))]);\n",
    "    v2=np.array([V[1][k][1] for k in range(len(V[1]))]);\n",
    "    norm1=(np.dot(v1,v1))**0.5;\n",
    "    norm2=(np.dot(v2,v2))**0.5;\n",
    "    cosine=np.dot(v1,v2)/(norm1*norm2);\n",
    "    return cosine;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for string matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS ALGORITHM TAKES AS INPUT THE DOCUMENT AND THE STRING YOU WANT TO SEARCH IN IT; IT ALSO TAKES A DICTIONARY\n",
    "#AS INPUT. THE DICTIONARY ASSIGNS NUMERICAL VALUES TO THE ALPHABETS SO THAT STRING MATCHING CAN BE DONE\n",
    "#USING HASH FUNCTIONS\n",
    "#THE FUNCTION RETURNS A LIST OF INDICES OF THE FORM [start, end] WHERE START INDICATES WHERE THE FIRST\n",
    "#CHARACTER OF THE PATTERN IS FOUND IN THE DOCUMENT, AND END INDICATES WHERE THE LAST CHARACTER OF THE \n",
    "#PATTERN OCCURS IN THE DOCUMENT.\n",
    "\n",
    "def RabinKarp(s,p,M):\n",
    "    n=len(s);\n",
    "    m=len(p);\n",
    "    ref=0;\n",
    "    h=0;\n",
    "    b=[];\n",
    "    \n",
    "    for i in range(m):\n",
    "        char=p[i];\n",
    "        M.setdefault(char,0);\n",
    "        val=M[char];\n",
    "        ref+=val*(2**(m-i-1));\n",
    "    \n",
    "    for j in range(m):\n",
    "        char=s[j];\n",
    "        M.setdefault(char,0);\n",
    "        val=M[char];\n",
    "        h+=val*(2**(m-j-1));\n",
    "    if ref==h:\n",
    "        b+=[[0,m]];\n",
    "    \n",
    "    for k in range(1,n-m):\n",
    "        c1=s[k-1];\n",
    "        c2=s[k+m-1];\n",
    "        M.setdefault(c1,0);\n",
    "        M.setdefault(c2,0);\n",
    "        v1=M[c1];\n",
    "        v2=M[c2];\n",
    "        h=(2*(h-v1*(2**(m-1)))+v2);\n",
    "        if h==ref:\n",
    "            b+=[[k,k+m]];\n",
    "  #  if b!=0:\n",
    "    #    print(s,p,b)\n",
    "    return b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION RETURNS THE NUMBER OF SENTENCES THAT ARE POSSIBLY THE SAME FOR THE 2 DOCUMENTS. \n",
    "#IT DOESN'T RETURN WHERE THESE SENTENCES OCCUR, SINCE THAT WAS A LITTLE HARD, BUT IT TELLS HOW MANY \n",
    "#SENTENCES ARE COMMON TO THE DOCUMENTS. AS A RESULT, IT IS EASY TO CHECK HOW MUCH OF THE DOCUMENTS WERE \n",
    "#DIRECTLY COPIED WITH MINOR CHANGES.\n",
    "\n",
    "def MatchStrings(doc1,doc2,M):\n",
    "    sdoc1=SentenceBreak(doc1);\n",
    "    sdoc2=SentenceBreak(doc2);\n",
    "    e='';\n",
    "    l1=len(sdoc1);\n",
    "    l2=len(sdoc2);\n",
    "    count=0;\n",
    "    s1=[e.join(fullCleanup(i)) for i in sdoc1];\n",
    "    d2=e.join(fullCleanup(doc2));\n",
    "    for i in s1:\n",
    "        b=RabinKarp(d2,i,M);\n",
    "        if len(b)!=0:\n",
    "            count+=1;\n",
    "    return [[\"Number of common sentences\",count],[\"Number of sentences in the first document:\",l1],[\"Number of sentences in the second document:\",l2]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyword search and deciding if the the two articles are related/ discuss the same topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION RETURNS THE 10 MOST FREQUENTLY OCCURING WORDS IN THE GIVEN DOCUMENT.\n",
    "#IT RETURNS THE WORD AND HOW MANY TIMES IT OCCURS IN THE DOCUMENT.\n",
    "#IT GIVES A GOOD IDEA ABOUT THE THEME OF THE DOCUMENTS.\n",
    "\n",
    "def HighFreq(doc):\n",
    "    L=Vectoriser(doc);\n",
    "    list=[[i,L[i]] for i in L];\n",
    "    def MaxFinder(l):\n",
    "        ind=0;\n",
    "        max=list[0][1];\n",
    "        word=l[0][0];\n",
    "        for i in range(len(l)):\n",
    "            if l[i][1]>max:\n",
    "                max=l[i][1];\n",
    "                ind=i;\n",
    "                word=l[i][0];\n",
    "        del l[ind];\n",
    "        return [word,max];\n",
    "    b=[];\n",
    "    for j in range(15):\n",
    "        if len(list)>0:  \n",
    "            b+=[MaxFinder(list)];\n",
    "        else:\n",
    "            break;\n",
    "    return b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION RETURNS THE COMMON WORDS OF THE TWO DOCUMENTS. \n",
    "#IT RETURNS ONLY THE HIGH FREQUENCY WORDS.\n",
    "\n",
    "def CommonWords(doc1,doc2):\n",
    "    freq1=HighFreq(doc1);\n",
    "    freq2=HighFreq(doc2);\n",
    "    common=[];\n",
    "    for i in freq1:\n",
    "        if len(freq2)>0:\n",
    "            for j in range(len(freq2)):\n",
    "                if i[0]==freq2[j][0]:\n",
    "                    common+=[i[0]];\n",
    "                    del freq2[j];\n",
    "                    break;\n",
    "    return common;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION IS AN OPTIONAL FUNCTION. IT TAKES AS INPUT A LIST OF KEYWORDS THAT MAY RELATE TO THE DOCUMENTS\n",
    "#USING WORDNET, THIS FUNCTION EXPANDS THAT LIST TO INCLUDE ALL THE SYNONYMS, OR RELATED WORDS OF THE KEYWORDS.\n",
    "\n",
    "def related(key):\n",
    "    newKey=[];\n",
    "    for i in key:\n",
    "        syn=wordnet.synsets(i);\n",
    "        l=[];\n",
    "        for words in syn:\n",
    "            l.append(words.lemmas()[0].name());\n",
    "            w1=words.hyponyms();\n",
    "            w2=words.part_meronyms();\n",
    "            w3=words.entailments();\n",
    "            w=w1+w2+w3;\n",
    "            for i in w:\n",
    "                l+=[i.lemmas()[0].name()];\n",
    "        newKey+=l;\n",
    "    return newKey;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to highlight the common words and key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION IS TO SIMPLIFY THE TASK OF HIGHLIGHTING THE COMMON WORDS. \n",
    "#IT HAS NO RELEVANCE TO THE ACTUAL PLAGIARISM DETECTION; IT IS, HOWEVER, NECESSARY FOR THE \n",
    "#PURPOSE OF HIGHLIGHTING.\n",
    "\n",
    "def MergeSort(l):\n",
    "    n=len(l);\n",
    "    if n==0 or n==1:\n",
    "        return l;\n",
    "    if n==2:\n",
    "        if l[0][1]>l[1][1]:\n",
    "            return [l[1],l[0]];\n",
    "        else:\n",
    "            return l;\n",
    "    else:\n",
    "        n1=n//2;\n",
    "        a1=l[0:n1];\n",
    "        a2=l[n1:n];\n",
    "        a1=MergeSort(a1);\n",
    "        a2=MergeSort(a2);\n",
    "        a=[];\n",
    "        while len(a1)>0 and len(a2)>0:\n",
    "            if a1[0][1]<=a2[0][1]:\n",
    "                a+=[a1[0]];\n",
    "                del a1[0];\n",
    "            else:\n",
    "                a+=[a2[0]];\n",
    "                del a2[0];\n",
    "        a=a+a1+a2;\n",
    "        return a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS FUNCTION COLOURS THE WORDS IN THE DOCUMENT. iT TAKES THE DOCUMENT AS INPUT, ALONG WITH\n",
    "#THE OUTPUT OF THE MATCHSTRINGS FUNCTION, AND THE FILE WHERE YOU WANT TO WRITE THE OUTPUT. \n",
    "\n",
    "def color(f,doc,b,j):\n",
    "    n=len(doc);\n",
    "    while j<n and len(b)>0:\n",
    "        count=0;\n",
    "        ind=0;\n",
    "        for i in range(0,len(b)):\n",
    "            if b[i][1]==j:\n",
    "                count+=1;\n",
    "                r=b[i][2]-j;\n",
    "                if doc[j-1]==\" \":\n",
    "                    if b[i][0]%3==0:\n",
    "                        for e in range(r):\n",
    "                            f.write(\"\"'<span style=\"background-color: green\">{}</span>'.format(doc[j+e]));\n",
    "                    elif b[i][0]%3==1:\n",
    "                        for e in range(r):\n",
    "                            f.write(\"\"'<span style=\"background-color: aqua\">{}</span>'.format(doc[j+e]));\n",
    "                    else:\n",
    "                        for e in range(r):\n",
    "                            f.write(\"\"'<span style=\"background-color: red\">{}</span>'.format(doc[j+e]));\n",
    "                    j+=r;\n",
    "                    del b[i];\n",
    "                    break;\n",
    "                else:\n",
    "                    for e in range(r):\n",
    "                        f.write(doc[j+e]);\n",
    "                    count+=1;\n",
    "                    j+=r;\n",
    "                    del b[i];\n",
    "                    break;\n",
    "        if count==0:\n",
    "            f.write(doc[j]);\n",
    "            j+=1;\n",
    "    return j;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tHE ACTUAL FUNCTION TO HIGHLIGHT THE WORDS.\n",
    "#THE INPUTS N1,N2,N3,N4 REPRESNT THE NAMES OF THE FILES WHERE YOU WANT TO STORE THE HIGHLIGHTED OUTPUT.\n",
    "#N1 IS FOR COMMON WORDS OF THE FIRST DOCUMENT, N2 IS FOR THE SECOND DOCUMENT.\n",
    "#THESE VARIABLES SHOULD BE STRINGS, AND BE OF THE FORM 'NAME_OF_FILE.HTML' ONLY.\n",
    "#N3 AND N4 ARE FOR HIGHLIGHTED KEYWORDS.\n",
    "#IT TAKES THE 2 DOCUMENTS AS INPUTS, ALONG WITH THE KEYWORD LIST, THE DICTIONARY FOR RABIN-KARP ALGORITHM.\n",
    "\n",
    "def HighLight(doc1,doc2,key,M,n1,n3):\n",
    "    n2='temp1.html'\n",
    "    n4='temp2.html'\n",
    "    d1=doc1.lower();\n",
    "    d2=doc2.lower();\n",
    "    Freq1=HighFreq(d1);\n",
    "    Freq2=HighFreq(d2);\n",
    "    Common=[];\n",
    "    for i in Freq1:\n",
    "        if len(Freq2)>0:\n",
    "            for j in range(len(Freq2)):\n",
    "                if Freq2[j][0]==i[0]:\n",
    "                    Common+=[i[0]];\n",
    "                    del Freq2[j];\n",
    "                    break;\n",
    "        else:\n",
    "            break;\n",
    "                \n",
    "    KeyWords=related(key);\n",
    "    b_temp1=[];\n",
    "    b_temp2=[];\n",
    "    for i in range(len(Common)):\n",
    "        b_temp1+=[[i,RabinKarp(d1,Common[i],M),RabinKarp(d2,Common[i],M)]];\n",
    "    for j in range(len(KeyWords)):\n",
    "        b_temp2+=[[j,RabinKarp(d1,KeyWords[j],M),RabinKarp(d2,KeyWords[j],M)]];\n",
    "    CommInd1=[];\n",
    "    CommInd2=[];\n",
    "    KeyInd1=[];\n",
    "    KeyInd2=[];\n",
    "    for el in b_temp1:\n",
    "        CommInd1+=[[el[0],i[0],i[1]] for i in el[1]];\n",
    "        CommInd2+=[[el[0],i[0],i[1]] for i in el[2]];\n",
    "    for el in b_temp2:\n",
    "        KeyInd1+=[[el[0],i[0],i[1]] for i in el[1]];\n",
    "        KeyInd2+=[[el[0],i[0],i[1]] for i in el[2]];\n",
    "    CommInd1=MergeSort(CommInd1);\n",
    "    CommInd2=MergeSort(CommInd2);\n",
    "    KeyInd1=MergeSort(KeyInd1);\n",
    "    KeyInd2=MergeSort(KeyInd2);\n",
    "    j1=0;\n",
    "    j2=0;\n",
    "    j3=0;\n",
    "    j4=0;\n",
    "    f1=open(n1,'w+');\n",
    "    f2=open(n2,'w+');\n",
    "    f3=open(n3,'w+');\n",
    "    f4=open(n4,'w+');\n",
    "    j1=color(f1,doc1,CommInd1,j1);\n",
    "    j2=color(f2,doc2,CommInd2,j2);\n",
    "    j3=color(f3,doc1,KeyInd1,j3);\n",
    "    j4=color(f4,doc2,KeyInd2,j4);\n",
    "    a1=len(doc1);\n",
    "    a2=len(doc2);\n",
    "    f1.close();\n",
    "    f2.close();\n",
    "    f3.close();\n",
    "    f4.close();\n",
    "    f1=open(n1,'a');\n",
    "    f2=open(n2,'a');\n",
    "    f3=open(n3,'a');\n",
    "    f4=open(n4,'a');\n",
    "    f1.write(doc1[j1:a1]);\n",
    "    f2.write(doc2[j2:a2]);\n",
    "    f3.write(doc1[j3:a1]);\n",
    "    f4.write(doc2[j4:a2]);\n",
    "    f1.close();\n",
    "    f2.close();\n",
    "    f3.close();\n",
    "    f4.close();\n",
    "    f1=open(n1,'a');\n",
    "    f2=open(n2,'r');\n",
    "    f3=open(n3,'a');\n",
    "    f4=open(n4,'r');\n",
    "    f1.write(\"<br><br>\")\n",
    "    f3.write(\"<br><br>\")\n",
    "    f1.write(f2.read());\n",
    "    f3.write(f4.read());\n",
    "    f1.close();\n",
    "    f2.close();\n",
    "    f3.close();\n",
    "    f4.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Number of common sentences', 2], ['Number of sentences in the first document:', 24], ['Number of sentences in the second document:', 22]]\n",
      "The most common words are: ['people', 'pandemic', 'coronavirus', 'cough', 'infect', 'covid', '2019', 'acute']\n",
      "Cosine similarity:  0.5868896084988103\n",
      "Percentage similarity:  39.92954962109474 %\n"
     ]
    }
   ],
   "source": [
    "f1=open(\"text1.txt\",\"r\")\n",
    "f2=open(\"text2.txt\",\"r\")\n",
    "s1=f1.read()\n",
    "s2=f2.read()\n",
    "tkey=\"\"#input(\"Enter keywords to search for:\")\n",
    "key=fullCleanup(tkey)\n",
    "print(MatchStrings(s1,s2,Map))\n",
    "common=CommonWords(s1,s2)\n",
    "print(\"The most common words are:\",common)\n",
    "cosine=CosineSimilarity(s1,s2)\n",
    "print(\"Cosine similarity: \",cosine)\n",
    "print(\"Percentage similarity: \",(math.pi/2-math.acos(cosine))/(math.pi/2)*100,\"%\")\n",
    "HighLight(s1,s2,key,Map,'op1.html','op2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter keywords to search for:lost, like\n"
     ]
    }
   ],
   "source": [
    "t1=\"i lost my keys. i like apples.\"\n",
    "t2=\"i misplaced my keys. i love apples.\"\n",
    "tkey=input(\"Enter keywords to search for:\")\n",
    "key=fullCleanup(tkey)\n",
    "HighLight(t1,t2,key,Map,'op1.html','op3.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common words are: ['court', 'criminal', 'bankruptcy', 'jurisdiction', 'case', 'instance', 'federal', 'state', 'legal', 'system']\n",
      "Cosine similarity:  0.8692279334592989\n",
      "29.630956023731834\n",
      "Percentage similarity:  67.07671552918686 %\n"
     ]
    }
   ],
   "source": [
    "s1=\"The legal system is made up of civil courts, criminal courts and specialty courts such as family law courts and bankruptcy court. Each court has its own jurisdiction, which refers to the cases that the court is allowed to hear. In some instances, a case can only be heard in one type of court. For example, a bankruptcy case must be heard in a bankruptcy court. In other instances, there may be several potential courts with jurisdiction. For example, a federal criminal court and a state criminal court would each have jurisdiction over a crime that is a federal drug offense but that is also an offense on the state level.\"\n",
    "s2=\"The legal system is comprised of criminal and civil courts and specialty courts like bankruptcy and family law courts. Every one of the courts is vested with its own jurisdiction. Jurisdiction means the types of cases each court is permitted to rule on. Sometimes, only one type of court can hear a particular case. For instance, bankruptcy cases an be ruled on only in bankruptcy court. In other situations, it is possible for more than one court to have jurisdiction. For instance, both a state and federal criminal court could have authority over a criminal case that is illegal under federal and state drug laws.\"\n",
    "common=CommonWords(s1,s2)\n",
    "print(\"The most common words are:\",common)\n",
    "cosine=CosineSimilarity(s1,s2)\n",
    "print(\"Cosine similarity: \",cosine)\n",
    "print(math.acos(cosine)*180/math.pi)\n",
    "print(\"Percentage similarity: \",(math.pi/2-math.acos(cosine))/(math.pi/2)*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
